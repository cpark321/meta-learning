{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils import MVTecMetaDataset, MVTecDataset\n",
    "from models import MVTecLearner\n",
    "\n",
    "device = 'cuda:0'\n",
    "data_dir = './data/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x, y):\n",
    "    remove_zero_losses = (x!=y)\n",
    "    x = x[remove_zero_losses]\n",
    "    y = y[remove_zero_losses]\n",
    "    loss = -(x.log() * y + (1 - x).log() * (1 - y))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataset(target_class, num_train_points):\n",
    "\n",
    "    normal_list_dir = [os.path.join(data_dir, target_class, 'train', 'good'), os.path.join(data_dir, target_class, 'test', 'good')]\n",
    "\n",
    "    test_dir = os.path.join(data_dir, target_class, 'test')\n",
    "    test_subfolders = next(os.walk(test_dir))[1]\n",
    "\n",
    "    abnormal_list_dir=[]\n",
    "\n",
    "    for item in test_subfolders:\n",
    "        if item != 'good':\n",
    "            abnormal_list_dir.append(os.path.join(data_dir, target_class, 'test', item))\n",
    "\n",
    "    NormalImgs = MVTecMetaDataset(normal_list_dir)\n",
    "    AbnormalImgs = MVTecMetaDataset(abnormal_list_dir)\n",
    "    \n",
    "    train_normal_set, val_normal_set = random_split(NormalImgs, [num_train_points, len(NormalImgs)-num_train_points])    \n",
    "    train_abnormal_set, val_abnormal_set = random_split(AbnormalImgs, [num_train_points, len(AbnormalImgs)-num_train_points])\n",
    "    \n",
    "    return train_normal_set, train_abnormal_set, val_normal_set, val_abnormal_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMvtecMaml(target_class, num_train_points, num_grad_update=1, maml=True):\n",
    "    \n",
    "    # num_grad_update = K  for evaluation\n",
    "\n",
    "    mvtec_learner = MVTecLearner(device=device)\n",
    "\n",
    "    if maml:\n",
    "        if target_class == 'capsule':\n",
    "            loadpath = \"./mvtec_saves/mvtec_targetcapsule_n2_k5_lr1e-07_final.pth\"\n",
    "        elif target_class == 'pill':\n",
    "            loadpath = \"./mvtec_saves/mvtec_targetpill_n2_k5_lr1e-07_final.pth\"\n",
    "        elif target_class == 'zipper':\n",
    "            loadpath = \"./mvtec_saves/mvtec_targetzipper_n2_k5_lr1e-07_final.pth\"\n",
    "        elif target_class == 'metal_nut':\n",
    "            loadpath = \"./mvtec_saves/mvtec_targetmetal_nut_n2_k5_lr1e-07_final.pth\"\n",
    "        mvtec_learner.load_state_dict(torch.load(loadpath, map_location=device))    \n",
    "\n",
    "    batch_size      = 2*num_train_points\n",
    "    lr_a            = 0.01\n",
    "\n",
    "    train_normal_set, train_abnormal_set, val_normal_set, val_abnormal_set  = TestDataset(target_class, num_train_points)\n",
    "    \n",
    "    count_correct_pred = 0\n",
    "    count_total_pred   = 0\n",
    "    \n",
    "    # 2.1 sample K datapoints from Ti\n",
    "    \n",
    "    num_train_batch = 5\n",
    "    \n",
    "    normal_sampler = DataLoader(train_normal_set, batch_size=int(num_train_points/num_train_batch), shuffle=True)\n",
    "    abnormal_sampler = DataLoader(train_abnormal_set, batch_size=int(num_train_points/num_train_batch), shuffle=True)    \n",
    "    \n",
    "    fast_weights = mvtec_learner.copy_model_weights()\n",
    "\n",
    "    for j in range(num_grad_update):\n",
    "        for i in range(num_train_batch):\n",
    "            normal_imgs, _ = next(iter(normal_sampler))\n",
    "            abnormal_imgs, _ = next(iter(abnormal_sampler))                    \n",
    "            \n",
    "            X_batch = torch.cat((normal_imgs, abnormal_imgs), dim=0).to(device)            \n",
    "            Y_batch = torch.tensor(np.concatenate((np.zeros([len(normal_imgs)]),np.ones([len(abnormal_imgs)]))), dtype=torch.float, device=device).view(-1,1)\n",
    "            Y_pred = mvtec_learner.forward_fast_weights(X_batch, fast_weights)\n",
    "            \n",
    "            train_loss = criterion(Y_pred, Y_batch)\n",
    "            grad = torch.autograd.grad(train_loss, fast_weights, create_graph=True)\n",
    "            fast_weights = mvtec_learner.update_fast_grad(fast_weights, grad, lr_a)  \n",
    "\n",
    "    # 3. evaluation\n",
    "    \n",
    "    num_eval_batch = 4\n",
    "    \n",
    "    normal_sampler = DataLoader(val_normal_set, batch_size=int(len(val_normal_set)/num_eval_batch), shuffle=False)\n",
    "    abnormal_sampler = DataLoader(val_abnormal_set, batch_size=int(len(val_abnormal_set)/num_eval_batch), shuffle=False)\n",
    "    \n",
    "    correct_sum=0\n",
    "    total_sum = 0\n",
    "    \n",
    "    for i in range(num_eval_batch):\n",
    "        normal_imgs, _ = next(iter(normal_sampler))\n",
    "        abnormal_imgs, _ = next(iter(abnormal_sampler))    \n",
    "\n",
    "        X_batch_eval = torch.cat((normal_imgs, abnormal_imgs), dim=0).to(device)\n",
    "        Y_batch_eval = torch.tensor(np.concatenate((np.zeros([len(normal_imgs)]),np.ones([len(abnormal_imgs)]))), dtype=torch.float, device=device).view(-1,1)\n",
    "\n",
    "        Y_pred_eval = mvtec_learner.forward_fast_weights(X_batch_eval, fast_weights)\n",
    "        Y_pred_eval = (Y_pred_eval > 0.5).float()\n",
    "\n",
    "        corr_pred  = (Y_batch_eval == Y_pred_eval).int().sum().item()\n",
    "        total_pred = len(Y_batch_eval)\n",
    "        \n",
    "        correct_sum+=corr_pred\n",
    "        total_sum+=total_pred\n",
    "\n",
    "    print(\"PREDICTION ACCURACY = {}\".format(correct_sum/total_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.5617647058823529\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml(target_class='capsule', num_train_points= 5, num_grad_update= 1, maml=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.3058823529411765\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('capsule', 5,1, maml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.7021276595744681\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('zipper', 5,1, maml=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.42819148936170215\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('zipper', 5,1, maml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.6792452830188679\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('pill', 5,1, maml=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.3938679245283019\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('pill', 5,1, maml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.4691358024691358\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('metal_nut', 5,1, maml=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ACCURACY = 0.28703703703703703\n"
     ]
    }
   ],
   "source": [
    "evaluateMvtecMaml('metal_nut', 5,1, maml=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
